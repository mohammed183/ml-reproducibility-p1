{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b011066-9c71-463d-829c-cdb4f5f215ee",
   "metadata": {},
   "source": [
    "## Experiment 3:\n",
    "\n",
    "In this experiment we test the claim *“Warm-starting neural networks saves resources and time, but lowers test accuracy compared to random initialized models”*. We train the model with two initialization and expect to see less training time and less test accuracy for the warm-starting model.\n",
    "\n",
    "We conduct an experiment to compare the effects of random initialization and warm-starting on online training, which is a common scenario in real time setting. We divide the **CIFAR-10** dataset into splits of 1000 samples each, and train a **ResNet18** model on each split until it reaches *99% training accuracy*. We incrementally add more splits to the training data until we exhaust the whole dataset. We record the training time and test accuracy for each split and analyze the differences between the two initialization methods.\n",
    "\n",
    "We reuse some components from the previous experiment as the **ResNet18** model from torchvision and the **Adam** optimizer from `torch.optim`, with cross entropy loss as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903079ce-8604-4691-90ff-9fc5a6757be7",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "We import the required packages as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdced6-aa8a-4eef-a6cc-c92ab10f4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432484b1-ad6b-4d36-bad5-0e4aa83549f7",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "The `get_cifar10_online_loaders` function accepts a `split_size` parameter and returns train, test and validation loaders. The train loader is a list of loaders with increasing number of samples, where each loader adds `split_size` more samples to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c019b1-0cec-4165-80b9-88acffd726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_online_loaders(split_size):\n",
    "    \"\"\"\n",
    "    This loads the whole CIFAR-10 into memory and returns train, validation and test data according to params\n",
    "    train is returned into several data loaders\n",
    "    @param split_size (int): size of train loaders\n",
    "\n",
    "    @returns dict() with train, validation and\n",
    "                test data loaders with keys `train_loaders`, `val_loader`, `test_loader`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalization and transformation functions\n",
    "    normalize_transform = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    \n",
    "    # Create train and test transforms\n",
    "    train_transform = transforms.Compose([transforms.ToTensor(), normalize_transform])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize_transform])\n",
    "    \n",
    "    # Loading datasets from torch vision\n",
    "    original_train_dataset = datasets.CIFAR10(root=os.path.join('data', 'cifar10_data'),\n",
    "                                              train=True, transform=train_transform, download=True)\n",
    "    original_test_dataset = datasets.CIFAR10(root=os.path.join('data', 'cifar10_data'),\n",
    "                                             train=False, transform=test_transform, download=True)\n",
    "    \n",
    "    # Validation split as 33% of train data\n",
    "    val_dataset_size = int(len(original_train_dataset) / 3)\n",
    "    train_dataset_size = len(original_train_dataset) - val_dataset_size\n",
    "    original_train_dataset, val_dataset = random_split(original_train_dataset,\n",
    "                                                       [train_dataset_size, val_dataset_size])\n",
    "\n",
    "    train_datasets = random_split(original_train_dataset,\n",
    "                                  [split_size for _ in range(train_dataset_size // split_size)] + [\n",
    "                                      train_dataset_size % split_size])\n",
    "    # Creating data loaders\n",
    "    loader_args = {\n",
    "        \"batch_size\": 128,\n",
    "    }\n",
    "    \n",
    "    # train loader for every train dataset\n",
    "    train_loaders = []\n",
    "    active_datasets = []\n",
    "    for train_dataset in train_datasets:\n",
    "        active_datasets.append(train_dataset)\n",
    "        train_loaders.append(torch.utils.data.DataLoader(\n",
    "            dataset=ConcatDataset(active_datasets),\n",
    "            shuffle=True,\n",
    "            **loader_args\n",
    "        ))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=original_test_dataset,\n",
    "        shuffle=False,\n",
    "        **loader_args)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        shuffle=False,\n",
    "        **loader_args)\n",
    "\n",
    "    return {\"train_loaders\": train_loaders,\n",
    "            \"test_loader\": test_loader,\n",
    "            \"val_loader\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc2c48-682f-46b7-a315-0aaf5b0eb9f7",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "We use some functions that were defined in previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419a182-b4bf-4a35-9dc7-45a521f6f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes predictions and true values to return accuracies\n",
    "def get_accuracy(logit, true_y):\n",
    "    pred_y = torch.argmax(logit, dim=1)\n",
    "    return (pred_y == true_y).float().mean()\n",
    "\n",
    "def eval_on_dataloader(device, criterion, model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given data loader and return the average loss and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    device: the device (cpu or gpu) to use for computation\n",
    "    criterion: the loss function to use\n",
    "    model: the model to evaluate\n",
    "    dataloader: the data loader to iterate over the data\n",
    "\n",
    "    Returns:\n",
    "    loss: the average loss over the data loader\n",
    "    accuracy: the average accuracy over the data loader\n",
    "    \"\"\"\n",
    "    # Lists to store accuracy and loss\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data_x, data_y) in enumerate(dataloader): \n",
    "        data_x = data_x.to(device) \n",
    "        data_y = data_y.to(device)\n",
    "        \n",
    "        # get the model output for the input data\n",
    "        model_y = model(data_x) \n",
    "        \n",
    "        # compute the loss and accuracy\n",
    "        loss = criterion(model_y, data_y)\n",
    "        batch_accuracy = get_accuracy(model_y, data_y)\n",
    "        \n",
    "        # append accuracy and loss to lists\n",
    "        accuracies.append(batch_accuracy.item()) \n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # compute average loss and accuracy\n",
    "    loss = np.mean(losses) \n",
    "    accuracy = np.mean(accuracies) \n",
    "    return loss, accuracy \n",
    "\n",
    "\n",
    "def train_one_epoch(device, model, optimizer, criterion, dataloader):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch on a given training data loader and return the average loss and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    device: the device (cpu or gpu) to use for computation\n",
    "    model: the model to train\n",
    "    optimizer: the optimizer to use for updating the weights\n",
    "    criterion: the loss function to use\n",
    "    train_dataloader: the training data loader to iterate over the training data\n",
    "\n",
    "    Returns:\n",
    "    train_loss: the average loss over the training data loader\n",
    "    train_accuracy: the average accuracy over the training data loader\n",
    "    \"\"\"\n",
    "    # Lists to store accuracy and loss\n",
    "    accuracies = []\n",
    "    losses = [] \n",
    "    \n",
    "    for batch_idx, (data_x, data_y) in enumerate(dataloader):\n",
    "        data_x = data_x.to(device) \n",
    "        data_y = data_y.to(device) \n",
    "        \n",
    "         # reset the gradients of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get the model output for the input data\n",
    "        model_y = model(data_x)\n",
    "        \n",
    "        # compute the loss and accuracy\n",
    "        loss = criterion(model_y, data_y)\n",
    "        batch_accuracy = get_accuracy(model_y, data_y)\n",
    "        \n",
    "        # compute the gradients and update model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # append accuracy and loss to lists\n",
    "        accuracies.append(batch_accuracy.item()) \n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # compute average loss and accuracy\n",
    "    loss = np.mean(losses) \n",
    "    accuracy = np.mean(accuracies) \n",
    "    return loss, accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b61a8-7847-4a78-b974-0a5e90640d4b",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "The `train_model_online` function performs an online learning experiment on the **CIFAR-10** dataset, using a **ResNet18** model and an **Adam** optimizer. The function uses the following new parameters:\n",
    "\n",
    "-   `init_type`: string indicating the type of initialization for the model. It can be either *random* or *warm*. If *random*, the model is reset for each split of data. If *warm*, the model is reused with the previous parameters.\n",
    "-   `split_size`: integer indicating the number of samples to add to the training data in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2afaa4-471f-4479-9568-f1da13d5dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_model_online(init_type='random', lr=0.001, split_size=1000, acc_threshold=0.99, random_seed=42):\n",
    "    experiment_dir = 'experiments/exp3'\n",
    "    # make experiment directory\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    # Set the seed\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Check if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "        print(\"CUDA Recognized\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Get the dataset\n",
    "    loaders = get_cifar10_online_loaders(split_size=split_size)\n",
    "\n",
    "    # Get the model\n",
    "    model = models.resnet18(num_classes=10).to(device)\n",
    "\n",
    "    # Create the loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Dictionary to hold results\n",
    "    results = {}\n",
    "    \n",
    "    # Online learning setup\n",
    "    number_of_samples_online = [0]\n",
    "    test_accuracies_online = [0]\n",
    "    training_times_online = [0]\n",
    "    \n",
    "    # Loop on all train loaders\n",
    "    for i, train_loader in enumerate(loaders['train_loaders']):\n",
    "        t_start = datetime.now()\n",
    "        n_train = (i + 1) * split_size\n",
    "        number_of_samples_online.append(n_train)\n",
    "        \n",
    "        # Reset model if training random initialization\n",
    "        if init_type == 'random':\n",
    "            model = models.resnet18(num_classes=10).to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        print(f\"{init_type.capitalize()}-Start training with {n_train} data.\")\n",
    "        \n",
    "        # Train model until convergence\n",
    "        stop_indicator = False\n",
    "        epoch = 0\n",
    "        while(not stop_indicator):\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"Starting training in epoch {epoch + 1}\")\n",
    "            train_loss, train_accuracy = train_one_epoch(device, model, optimizer, criterion,\n",
    "                                                         train_loader)\n",
    "            epoch += 1\n",
    "            \n",
    "            if train_accuracy >= acc_threshold:\n",
    "                print(f\"Convergence condition met. Training accuracy > {100 * acc_threshold}\")\n",
    "                stop_indicator = True\n",
    "                    \n",
    "        # Calculate train time time\n",
    "        t_end = datetime.now()\n",
    "        training_time = (t_end - t_start).total_seconds()\n",
    "        \n",
    "        # Get test accuracy and append results\n",
    "        test_loss, test_accuracy =  eval_on_dataloader(device, criterion, model, loaders['test_loader'])\n",
    "        test_accuracies_online.append(test_accuracy * 100)\n",
    "        training_times_online.append(training_time)        \n",
    "\n",
    "    # Add to results\n",
    "    results[\"test_accuracies_online\"] = test_accuracies_online\n",
    "    results[\"training_times_online\"] = training_times_online\n",
    "    results[\"n_samples_online\"] = number_of_samples_online\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c697996-963e-480a-b573-0d3772ff48b3",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Before running the experiment we create a parameter table to store the parameter values from the paper that we will use in the next few cells.\n",
    "\n",
    "|         Model         | init_type 🆕 | Learning rate | Optimizer | Training accuracy | split size 🆕 |\n",
    "|:----------------:|:---------:|:---------:|:------:|:-------------:|:---------:|\n",
    "|     Warm-Starting     |     warm     |     0.001     |   Adam    |        99%        |     1000      |\n",
    "| Random initialization |    random    |     0.001     |   Adam    |        99%        |     1000      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbec11-1832-4c9b-8793-1c44be08b402",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "We start by training with **random** initialization using the previous function and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc625802-19b8-4c16-a9cb-2be27458993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold results\n",
    "results={}\n",
    "\n",
    "# Train on cifar10 for threshold 0.99\n",
    "results['random'] = train_model_online(init_type='random', lr=0.001, split_size=1000, acc_threshold=0.99, random_seed=42)\n",
    "\n",
    "# Save the outputs in a json file\n",
    "with open(\"experiments/exp3/results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63995d1-4c0e-4283-8324-6b518ab9eb63",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Next, we train with **warm-starting** models and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d2e2b-6f93-4259-8452-7ebbba7f476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on cifar10 for threshold 0.99\n",
    "results['warm'] = train_model_online(init_type='warm', lr=0.001, split_size=1000, acc_threshold=0.99, random_seed=42)\n",
    "\n",
    "# Save the outputs in a json file\n",
    "with open(\"experiments/exp3/results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdebd3-0e31-416e-81eb-2d88e444d984",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "We plot the figure from the original paper using the data we obtained earlier and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34425afa-78ad-471c-9337-714e70df38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from json file\n",
    "with open(\"experiments/exp3/results.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Create figure \n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# divide the number of samples to decrease them to two integers\n",
    "n_warm = np.array(results['warm']['n_samples_online']) / 1000\n",
    "n_random = np.array(results['random']['n_samples_online']) / 1000\n",
    "\n",
    "# Left plot accuracy comparison\n",
    "axs[0].plot(n_warm, results['warm']['test_accuracies_online'], label='warm start', color='C0')\n",
    "axs[0].plot(n_random, results['random']['test_accuracies_online'], label='random', color='C1')\n",
    "axs[0].set_ylabel(\"Test Accuracy\")\n",
    "axs[0].set_xlabel(\"Number of Samples (thousands)\")\n",
    "\n",
    "# Right plot time comparison\n",
    "axs[1].plot(n_warm, results['warm']['training_times_online'], label='warm start', color='C0')\n",
    "axs[1].plot(n_random, results['random']['training_times_online'], label='random', color='C1')\n",
    "axs[1].set_ylabel(\"Train Time (seconds)\")\n",
    "axs[1].set_xlabel(\"Number of Samples (thousands)\")\n",
    "\n",
    "# Plot and save\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(f\"experiments/exp3/cifar10-99.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1551e-280a-4c68-8ca3-f81c44ffcd28",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "**How well do the results support the qualitative claim? How close are the numerical values to the ones in the original paper? 🤔**\n",
    "\n",
    "**We listed the parameter values we used in the experiment in the parameter table. Can you locate these values in the paper text? 🔍**\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09eb679-5acd-4224-9e0d-e725f3f44055",
   "metadata": {},
   "source": [
    "### Things to try: 🧪\n",
    "\n",
    "In this experiment you can:\n",
    "\n",
    "-   Change the learning rate and observe what effects it have on the experiment.\n",
    "-   Experiment other `split_size` values and see if it affects the results of the generalization gap\n",
    "-   Try different `acc_threshold` values and see how they affect the training time and the generalization gap\n",
    "-   Change the random seed to test the sensitivity\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2655e3d-a1da-4f23-9c99-c04f411ab32a",
   "metadata": {},
   "source": [
    "### There are more claims in the paper. Identify one of those claims and validate its qualitative and quantitative versions! 🧐\n",
    "\n",
    "Hint: You can find some of the functions that we used helpful. At least one claim doesn’t need any new functions to run. If you want to try another experiment where you need a logistic regression model, you can use the MLP class to create a logistic regression model:  \n",
    "`logistic = MLP(input_dim, num_classes, hidden_units=[])`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
